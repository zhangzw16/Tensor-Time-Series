{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "导入必要的包，设置数据集和输出路径和需要分析的数据集列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from statsmodels.tsa.tsatools import detrend\n",
    "from statsmodels.tsa.stattools import adfuller, kpss, acf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "root_pth = '/nas/datasets/Tensor-Time-Series-Dataset/Processed_Data'\n",
    "output_csv_pth = '/home/wangzihan/workspace/TTS_results/csv'\n",
    "output_img_pth = '/home/wangzihan/workspace/TTS_results/imgs'\n",
    "dataset_list = ['JONAS_NYC_taxi', 'JONAS_NYC_bike', 'METRO_HZ', 'METRO_SH',\n",
    "                'PEMS03', 'PEMS07', \n",
    "                'ETT_hour', 'electricity', 'weather',\n",
    "                'nasdaq100'\n",
    "                ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考ProbTS的思路，将MTS/Tensor数据分解为1D时间序列的集合，将1D时间序列加窗分段，利用FFT检测每一小段的周期并进行STL分解，计算trend和seasonality strength，将两者的均值和方差做为数据集的特征。\n",
    "\n",
    "DataParserBase实现了加窗分段，stride参数表示相邻窗之间的间隔（stride默认为1时包含了所有可能的分段，但计算时间太长了）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataParserBase:\n",
    "    def __init__(self, dataset_name:str) -> None:\n",
    "        # get data from pkl file \n",
    "        pkl_name = dataset_name + '.pkl'\n",
    "        pkl_path = os.path.join(root_pth, dataset_name, pkl_name)\n",
    "        if not os.path.exists(pkl_path):\n",
    "            raise FileExistsError(f\"Can not find file: {pkl_path}\")\n",
    "        with open(pkl_path, 'rb') as file:\n",
    "            self.data_pkl = pkl.load(file)\n",
    "            self.data = self.data_pkl['data']\n",
    "        self.transform_data()\n",
    "    \n",
    "    # treat data as a collection of 1D time series tobtain statistics of channels\n",
    "    def transform_data(self):\n",
    "        temp = self.data.reshape(self.data.shape[0], -1, 1)\n",
    "        self.data = np.squeeze(temp, axis=-1)\n",
    "        self.data_shape =self.data.shape\n",
    "        self.timesteps = self.data_shape[0]\n",
    "        self.channel_nums = self.data_shape[1]\n",
    "    \n",
    "    def get_data_shape(self):\n",
    "        return self.data_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STParser类实现了时间序列周期的检测以及trend和seasonality的计算，其中get_period()方法来自tasks/data_analysis，取FFT谱的最大值为season周期。\n",
    "分解序列时，先检测序列season周期period，再以period为参数进行STL分解（seasonal smoother长度取最接近period的奇数），得到三个分量后计算seasonality和trend strength值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class STParser(DataParserBase):\n",
    "    def __init__(self, dataset_name:str, window_size, stride=0) -> None:\n",
    "        super().__init__(dataset_name, window_size, stride)\n",
    "    \n",
    "    def get_period_acf(self, series, verbose=False):\n",
    "        # This method generally follows the steps in the paper:\n",
    "        # Characteristic-Based Clustering for Time Series Data (2006)\n",
    "        # TODO: can't cope well with shorter sequences\n",
    "        # 1. detrend data\n",
    "        data_detrend = detrend(series,order=1)\n",
    "        ser_len = data_detrend.shape[0]\n",
    "        maxlag = max(int(ser_len/3))\n",
    "        # 2. calculate autocorrelation function (maxlag up to 1/3 series length)\n",
    "        acorr = acf(data_detrend, nlags=maxlag, fft=True)\n",
    "        # 3. find peaks and trough in acf and determine period according to prominence\n",
    "        from scipy.signal import find_peaks\n",
    "        corr_peaks = find_peaks(acorr, height=0.1, distance=12)[0]\n",
    "        no_season = False\n",
    "        period = 1 # period default to 1 (no seasonality)\n",
    "        for i in range(1, corr_peaks.shape[0]):\n",
    "            seg = acorr[corr_peaks[i-1] : corr_peaks[i]]\n",
    "            trough = np.min(seg)\n",
    "            if (abs(trough-corr_peaks[i]) > 0.1):\n",
    "                period = corr_peaks[i]\n",
    "                break\n",
    "            no_season = (i==(corr_peaks.shape[0]-1))\n",
    "        return period if not no_season else 1\n",
    "    \n",
    "    def get_period(self, ts, k=1):\n",
    "        ts = detrend(ts, order=1)\n",
    "        # 计算FFT\n",
    "        if np.nonzero(ts)[0].shape[0] == 0:\n",
    "            return np.ones(k), np.ones(k)\n",
    "        fft = np.abs(np.fft.fft(ts, axis=0))\n",
    "        frequencies = np.fft.fftfreq(len(ts))\n",
    "\n",
    "        # 找到最大的k个频率\n",
    "        indices = np.argsort(np.abs(fft[1:-1]))[-k:]\n",
    "        periods = (1 / (frequencies[indices]+1e-10) if frequencies[indices] != 0 else np.array([1]))\n",
    "        strength = fft[indices]/np.sum(fft)\n",
    "        return np.abs(periods.astype(int))\n",
    "\n",
    "    def decompose(self, seg):\n",
    "        trd = []\n",
    "        ses = []\n",
    "        for i in range(0, self.channel_nums):\n",
    "            ser = seg[:, i]\n",
    "            if np.all(ser - np.mean(ser) == 0):\n",
    "                trd.append(0)\n",
    "                ses.append(0)\n",
    "            else:\n",
    "                period = self.get_period(ser)[0]\n",
    "                L = 2 * (period // 2) + 1\n",
    "                if period != 1:\n",
    "                    stl = STL(ser, period = int(period), seasonal = max(L, 7)).fit()\n",
    "                    seasonal, trend, resid = stl.seasonal, stl.trend, stl.resid\n",
    "                    # seasonality and trend strength\n",
    "                    val_trd = 1- (np.var(resid)/np.var(trend+resid))\n",
    "                    trd.append((val_trd if val_trd > 0 else 0))\n",
    "                    val_ses = 1- (np.var(resid)/np.var(seasonal+resid))\n",
    "                    ses.append((val_ses if val_ses > 0 else 0))\n",
    "                else:\n",
    "                    resid = detrend(ser, order=1)\n",
    "                    trend = ser - resid\n",
    "                    # seasonality and trend strength\n",
    "                    val_trd = 1- (np.var(resid)/np.var(trend+resid))\n",
    "                    trd.append((val_trd if val_trd > 0 else 0))\n",
    "                    ses.append(0)\n",
    "        return trd, ses\n",
    "    \n",
    "    def st_parse(self):\n",
    "        all_trd = []\n",
    "        all_ses = []\n",
    "        print(f\"Start parsing dataset: {self.dataset_name}\")\n",
    "        print(f\"iter nums: {len(range(0, self.timesteps, self.stride))}\")\n",
    "        for elems in tqdm(self.loader):\n",
    "            trd, ses = self.decompose(elems)\n",
    "            all_trd = all_trd + trd\n",
    "            all_ses = all_ses + ses\n",
    "        all_trd = np.array(all_trd)\n",
    "        all_ses = np.array(all_ses)\n",
    "        sm = np.mean(all_ses)\n",
    "        sv = np.var(all_ses)\n",
    "        tm = np.mean(all_trd)\n",
    "        tv = np.var(all_trd)\n",
    "        return sm, sv, tm, tv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "遍历数据集列表并输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start parsing dataset: JONAS_NYC_taxi\n",
      "iter nums: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [07:52,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seasonal mean: 0.36480094834370064, seasonal var: 0.028795999364248745\n",
      "trend mean: 0.2678069947183953, trend var: 0.034050372499239236\n",
      "Start parsing dataset: JONAS_NYC_bike\n",
      "iter nums: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [06:22,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seasonal mean: 0.2664028903791252, seasonal var: 0.03387400936294714\n",
      "trend mean: 0.14804500721195502, trend var: 0.019789749294984373\n",
      "Start parsing dataset: METRO_HZ\n",
      "iter nums: 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "77it [01:47,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seasonal mean: 0.30468968511042055, seasonal var: 0.03218503090800619\n",
      "trend mean: 0.2424300875566895, trend var: 0.026542667808434027\n",
      "Start parsing dataset: METRO_SH\n",
      "iter nums: 280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "280it [24:30,  5.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seasonal mean: 0.2925391435840112, seasonal var: 0.0173356560822418\n",
      "trend mean: 0.26250950378993154, trend var: 0.01665480604176324\n",
      "Start parsing dataset: PEMS03\n",
      "iter nums: 1092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1092it [24:29,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seasonal mean: 0.09108738143510978, seasonal var: 0.062394588874263086\n",
      "trend mean: 0.2021890686861127, trend var: 0.08089491909702981\n",
      "Start parsing dataset: PEMS07\n",
      "iter nums: 1176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1176it [1:54:45,  5.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seasonal mean: 0.17734584686491675, seasonal var: 0.11033743190138805\n",
      "trend mean: 0.278869273251859, trend var: 0.12393006236097137\n",
      "Start parsing dataset: ETT_hour\n",
      "iter nums: 726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "726it [00:41, 17.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seasonal mean: 0.4015875245608988, seasonal var: 0.0635661592955661\n",
      "trend mean: 0.391413566403501, trend var: 0.051206288890890864\n",
      "Start parsing dataset: electricity\n",
      "iter nums: 1096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1096it [40:10,  2.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seasonal mean: 0.5281561285203609, seasonal var: 0.06787297025035276\n",
      "trend mean: 0.250130570098088, trend var: 0.03469123818187717\n",
      "Start parsing dataset: weather\n",
      "iter nums: 2196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2196it [15:31,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seasonal mean: 0.5810504317295482, seasonal var: 0.15616022223444742\n",
      "trend mean: 0.5899956520709586, trend var: 0.11314750541944754\n",
      "Start parsing dataset: nasdaq100\n",
      "iter nums: 3112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3112it [4:59:20,  5.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seasonal mean: 0.32000442523891476, seasonal var: 0.147398157908286\n",
      "trend mean: 0.5305769569932318, trend var: 0.11868567869620894\n",
      "Finished parsing all datasets\n"
     ]
    }
   ],
   "source": [
    "class Aggregator:\n",
    "    def __init__(self, dataset_list: list) -> None:\n",
    "        self.dataset_list = dataset_list\n",
    "    \n",
    "    def st_to_csv(self, output_pth, window_size, stride=0, verbose=True, exp_id=0):\n",
    "        with open(os.path.join(output_pth, 'dataset_stats_' + str(exp_id) + '.csv'), 'w') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(['dataset_name', 'seasonality_mean', 'seasonality_var', 'trend_mean', 'trend_var'])\n",
    "                for elems in self.dataset_list:\n",
    "                    parser = STParser(elems, window_size, stride)\n",
    "                    sm, sv, tm, tv = parser.st_parse()\n",
    "                    if verbose:\n",
    "                        print(f\"seasonal mean: {sm}, seasonal var: {sv}\")\n",
    "                        print(f\"trend mean: {tm}, trend var: {tv}\") \n",
    "                    writer.writerow([f'{elems}', sm, sv, tm, tv])\n",
    "                writer.writerow([f'window_size: {window_size}'])\n",
    "                writer.writerow([f'stride: {stride}'])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    aggregator = Aggregator(dataset_list)\n",
    "    aggregator.st_to_csv(output_csv_pth, window_size=336, stride=24, exp_id=4, verbose=True)\n",
    "    print(\"Finished parsing all datasets\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TTS-Plot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
